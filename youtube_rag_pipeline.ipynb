{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6c0886a0",
      "metadata": {
        "id": "6c0886a0"
      },
      "source": [
        "# YouTube RAG Pipeline\n",
        "\n",
        "Pipeline\n",
        "1. **Loading Data**\n",
        "2. **Chunking**\n",
        "3. **Embeddings** (OpenAI-Embeddings)\n",
        "4. **VectorDB** (Chroma)\n",
        "5. **Retriever**\n",
        "6. **LLM** (OpenAI Chat-Model)\n",
        "7. **Chain** (Conversational Retrieval)\n",
        "8. **Memory**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. YouTube videos / transcripts"
      ],
      "metadata": {
        "id": "l2dqM0Be1PI-"
      },
      "id": "l2dqM0Be1PI-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "fHjZjvQ21l3C"
      },
      "id": "fHjZjvQ21l3C"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api chromadb sentence-transformers transformers accelerate torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR0yL9Me1vP-",
        "outputId": "36dd89af-6001-4086-8433-9e2f71ea2304"
      },
      "id": "rR0yL9Me1vP-",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.3.5)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (2.32.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.10)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.29.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "from youtube_transcript_api import (\n",
        "    YouTubeTranscriptApi,\n",
        "    TranscriptsDisabled,\n",
        "    NoTranscriptFound,\n",
        ")\n",
        "\n",
        "import pandas as pd\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
      ],
      "metadata": {
        "id": "eXO5JhUm1egX"
      },
      "id": "eXO5JhUm1egX",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "YouTube ingestion\n",
        "- URL -> video_id\n",
        "- video_id -> transcript (list)\n",
        "- transcript -> plain text"
      ],
      "metadata": {
        "id": "qFHwe7lD2TjT"
      },
      "id": "qFHwe7lD2TjT"
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the YouTube video ID from URL formats\n",
        "def extract_video_id(url: str) -> str:\n",
        "    parsed = urlparse(url)\n",
        "\n",
        "    # Short youtu.be links\n",
        "    if parsed.netloc in (\"youtu.be\", \"www.youtu.be\"):\n",
        "        return parsed.path.lstrip(\"/\")\n",
        "\n",
        "    # Regular youtube.com links\n",
        "    if parsed.netloc in (\"www.youtube.com\", \"youtube.com\", \"m.youtube.com\"):\n",
        "        qs = parse_qs(parsed.query)\n",
        "        vid = qs.get(\"v\", [None])[0]\n",
        "        if vid:\n",
        "            return vid\n",
        "\n",
        "    raise ValueError(f\"Could not extract video_id from URL: {url}\")\n",
        "\n",
        "#Convert a transcript (list of {text, start, duration}) to a single text string\n",
        "def transcript_to_text(transcript, include_timestamps: bool = False) -> str:\n",
        "    lines = []\n",
        "    for entry in transcript:\n",
        "        if include_timestamps:\n",
        "            start = entry[\"start\"]\n",
        "            lines.append(f\"[{start:.1f}s] {entry['text']}\")\n",
        "        else:\n",
        "            lines.append(entry[\"text\"])\n",
        "    return \" \".join(lines)\n",
        "\n",
        "\n",
        "#Fetch transcript for a single video_id and turn it into plain text.\n",
        "def fetch_transcript_text(video_id: str, languages=None) -> str:\n",
        "    try:\n",
        "        ytt_api = YouTubeTranscriptApi()\n",
        "\n",
        "        # If you don't care about language, you can call ytt_api.fetch(video_id) without languages\n",
        "        if languages is None:\n",
        "            fetched = ytt_api.fetch(video_id)\n",
        "        else:\n",
        "            fetched = ytt_api.fetch(video_id, languages=languages)\n",
        "\n",
        "        # `fetched` is a FetchedTranscript object with `.snippets`\n",
        "        # Convert to the same structure transcript_to_text() expects\n",
        "        transcript = [\n",
        "            {\"text\": s.text, \"start\": s.start, \"duration\": s.duration}\n",
        "            for s in fetched.snippets\n",
        "        ]\n",
        "\n",
        "        return transcript_to_text(transcript, include_timestamps=False)\n",
        "\n",
        "    except TranscriptsDisabled:\n",
        "        raise RuntimeError(f\"Transcripts are disabled for video_id={video_id}\")\n",
        "    except NoTranscriptFound:\n",
        "        raise RuntimeError(f\"No transcript found for video_id={video_id} in languages={languages}\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error fetching transcript for {video_id}: {e}\")\n"
      ],
      "metadata": {
        "id": "Bs8Ik8rc2fwc"
      },
      "id": "Bs8Ik8rc2fwc",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store transcripts in Chroma"
      ],
      "metadata": {
        "id": "c_LlEnne4kxE"
      },
      "id": "c_LlEnne4kxE"
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Chroma collection from a DataFrame with columns 'video_id', 'url', 'transcript'\n",
        "def build_chroma_collection_from_df(df: pd.DataFrame, collection_name: str = \"youtube_videos\"):\n",
        "\n",
        "    # 2.1 Set up Chroma client (in-memory for now; for persistence use PersistentClient)\n",
        "    client = chromadb.Client()\n",
        "\n",
        "    # 2.2 Define an embedding function (SentenceTransformer)\n",
        "    embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "        model_name=\"all-MiniLM-L6-v2\"\n",
        "    )\n",
        "\n",
        "    # 2.3 Create (or recreate) the collection\n",
        "    # If collection exists, delete it to start fresh\n",
        "    existing = [c.name for c in client.list_collections()]\n",
        "    if collection_name in existing:\n",
        "        client.delete_collection(collection_name)\n",
        "\n",
        "    collection = client.create_collection(\n",
        "        name=collection_name,\n",
        "        embedding_function=embedding_func,\n",
        "    )\n",
        "\n",
        "    # 2.4 Add documents to collection\n",
        "    # Use video_id as id, transcript as document\n",
        "    documents = df[\"transcript\"].tolist()\n",
        "    ids = df[\"video_id\"].tolist()\n",
        "    metadatas = df[[\"video_id\", \"url\"]].to_dict(orient=\"records\")\n",
        "\n",
        "    collection.add(\n",
        "        documents=documents,\n",
        "        ids=ids,\n",
        "        metadatas=metadatas,\n",
        "    )\n",
        "\n",
        "    print(f\"Added {len(documents)} transcripts to Chroma collection '{collection_name}'.\")\n",
        "    return collection"
      ],
      "metadata": {
        "id": "b8ST4sVL4opB"
      },
      "id": "b8ST4sVL4opB",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ingest_youtube_videos(urls, languages=\"en, de\") -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for url in urls:\n",
        "        try:\n",
        "            video_id = extract_video_id(url)\n",
        "            transcript = fetch_transcript_text(video_id, languages=languages)\n",
        "            rows.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"url\": url,\n",
        "                \"transcript\": transcript,\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {url}: {e}\")\n",
        "    return pd.DataFrame(rows)\n"
      ],
      "metadata": {
        "id": "5jefkcqOe_z4"
      },
      "id": "5jefkcqOe_z4",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transcribe"
      ],
      "metadata": {
        "id": "s6UWolFA6cv3"
      },
      "id": "s6UWolFA6cv3"
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # ---- 1) Ingest multiple videos ----\n",
        "    video_urls = [\n",
        "        # add YouTube URLs here:\n",
        "        \"https://www.youtube.com/watch?v=enD8mK9Zvwo\",\n",
        "        \"https://www.youtube.com/watch?v=ZdjJdoEwCY4\",\n",
        "\n",
        "    ]\n",
        "\n",
        "    df_videos = ingest_youtube_videos(video_urls, languages=[\"en\"])\n",
        "    print(\"\\nIngested videos DataFrame:\")\n",
        "    print(df_videos.head())\n",
        "\n",
        "    if df_videos.empty:\n",
        "        raise SystemExit(\"No videos ingested successfully â€“ check URLs or transcripts settings.\")\n",
        "\n",
        "    # ---- 2) Build Chroma collection ----\n",
        "    collection = build_chroma_collection_from_df(df_videos, collection_name=\"youtube_videos\")\n",
        "\n",
        "    print(\"\\nChroma collection is ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB4vj0G-6cAW",
        "outputId": "40b60353-ff69-4d28-9e0d-a4f64250a082"
      },
      "id": "TB4vj0G-6cAW",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ingested videos DataFrame:\n",
            "      video_id                                          url  \\\n",
            "0  enD8mK9Zvwo  https://www.youtube.com/watch?v=enD8mK9Zvwo   \n",
            "1  ZdjJdoEwCY4  https://www.youtube.com/watch?v=ZdjJdoEwCY4   \n",
            "\n",
            "                                          transcript  \n",
            "0  One of the most important parts of a job appli...  \n",
            "1  so going on a job interview has got to be one ...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 2 transcripts to Chroma collection 'youtube_videos'.\n",
            "\n",
            "Chroma collection is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_videos.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "FV1jSMsL-bgG",
        "outputId": "10e419a7-66ca-477c-b360-8267048e7de0"
      },
      "id": "FV1jSMsL-bgG",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      video_id                                          url  \\\n",
              "0  enD8mK9Zvwo  https://www.youtube.com/watch?v=enD8mK9Zvwo   \n",
              "1  ZdjJdoEwCY4  https://www.youtube.com/watch?v=ZdjJdoEwCY4   \n",
              "\n",
              "                                          transcript  \n",
              "0  One of the most important parts of a job appli...  \n",
              "1  so going on a job interview has got to be one ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d38f04de-4b96-45a4-bb70-2295325d1d58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "      <th>url</th>\n",
              "      <th>transcript</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>enD8mK9Zvwo</td>\n",
              "      <td>https://www.youtube.com/watch?v=enD8mK9Zvwo</td>\n",
              "      <td>One of the most important parts of a job appli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ZdjJdoEwCY4</td>\n",
              "      <td>https://www.youtube.com/watch?v=ZdjJdoEwCY4</td>\n",
              "      <td>so going on a job interview has got to be one ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d38f04de-4b96-45a4-bb70-2295325d1d58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d38f04de-4b96-45a4-bb70-2295325d1d58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d38f04de-4b96-45a4-bb70-2295325d1d58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ca533d93-475d-43d7-9e3a-35da5c9e5e70\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca533d93-475d-43d7-9e3a-35da5c9e5e70')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ca533d93-475d-43d7-9e3a-35da5c9e5e70 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_videos",
              "summary": "{\n  \"name\": \"df_videos\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"video_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ZdjJdoEwCY4\",\n          \"enD8mK9Zvwo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"https://www.youtube.com/watch?v=ZdjJdoEwCY4\",\n          \"https://www.youtube.com/watch?v=enD8mK9Zvwo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"so going on a job interview has got to be one of the most nerve-wracking things you'll do and so I want to give you three different tips on what you could do to crush your next job interview from an employer point of view not the employee because I've done hundreds if not thousands of interviews and I can tell you what worked and what didn't work so let's get right into it think about the three steps as before the interview during the interview and after the interview let's first talk about before the interview I the employer loved it when the person wanted to get the job has done a research on the company for instance I said what a person did that then I was interviewing them they were hiring for a CFO position with our company the amount of research this person had done was so impressive I can't even tell you he knew stories articles employees leaders challenges everything so I'm sinners saying this is how this person does research imagine if they work with us how much research they're gonna do on systems we need technologies we need this is very impressive I like this guy and so before him coming for the interview I got an email on LinkedIn saying my name is such-and-such I notice your inner your job posting I am really looking for the meeting with you on the CFO position for this company and we met I was very impressed by him okay so step number one do a lot of research number two during the interview overselling only works if you're going on a date with a girl or a guy and by the way if you oversell yourself that relationships gonna be a very short sale you gotta be kind of honest about what you're doing with the business and who you are so I sat with somebody and I said how much you know about this have to be honest with you I don't know a lot about this but I can tell you what I know a lot about boom boom boom what that told me what this person is I'm getting somebody that's gonna be very direct very honest and they know what they don't know they know what they do no wonder geyser was interviewing he said look this software I don't know about these areas I am very good at but with this all I need to do is go to a one-week course and I would get very good at this because one thing about me is I don't want the fastest learners I know and I can't wait to introduce that to you good I like that okay so don't oversell your superior self and find a way to match the mead with what your values and principles and what would your gifts and strengths that you bring in match those two together let me give you the last one you after the interview I had seven job interviews I did last week that I was looking for right only one of them messaged me back afterwards and said the following they said thank you so much for your time today and by the way this was the most qualified one out of all of them how impressive is this the person that's the most qualified who has worked with the biggest account as the most qualified person for this position was the only one that sent me the email and he said I just want you to I really enjoyed our time together I am the person you want not only do I want this job I am really looking forward to this because I can see myself bringing on a lot of value to the company I hope I get a chance to meet with you on a second interview regardless I wish you all the best sincerely dah dah dah I said you know what purely classy on a message like this it made me when we set then as the employer when we sat down on our board meeting and the investors and everybody was looking at everybody and they had already done the reference calls they said who are you impressed with I said well the only person that sent me a note afterwards was this person so I want you to think about it when you're going on your next job interview think about the before why because it separates you from everybody else if you do your research think about your during con overselling why because it gives you credibility with the person you're working with knowing you're forthright and there's not gonna be any surprises because if you oversell and we work and we realize you were over selling you get fired fast and you don't want to get fired fights because that doesn't look good on a resume and last but not least on the after send that note why because only a few people do it those three tips are the tips I got for you to go out and crush your next job interview [Music] you [Music]\",\n          \"One of the most important parts of a job application is the job interview. In this video you will learn what you can expect from an interview and get useful tips to help you prepare better. The job interview starts right at the first impression. Imagine you have arrived on time and you're ready to greet your new employer: how do you do this? Research shows that smiling, eye contact and giving a firm handshake are crucial for a good first impression. For example, people with a strong handshake are generally better appraised. During the interview, your nonverbal communication remains very important. Examples are an active sitting position and making eye contact with each person in the room. The following three topics are almost always discussed during the job interview: 1) Your life course: by asking questions about your background and experience, the employer tries to get a clearer image of you; what have you done in your life, why? What kind of person are you and what qualities do you have? 2) Your motivation: the employer will also ask questions about your motivation. Why do you want to work with this organization? Why does this position appeal to you? It is important that you have a thoughtful answer to these questions. Your motivation also becomes apparent from the knowledge that you have about the company and its activities. 3) competencies: the employer wants to know if you have the skills and personal characteristics that are needed for the job. You demonstrate these by using the STAR-method. The employer also evaluates during the conversation whether he or she will work well with you and whether you will fit into the team. An employer will be more likely to select you when there is a good conversation dynamic. One way to achieve this is by giving short and powerful answers. The interviewer can then ask follow-up questions where necessary. Try to engage in conversation with all the interview attendants by asking them questions during, or at the end of the conversation. In order to focus on your conversation partners and your nonverbal communication, you need to be well prepared. Below you'll find an overview of the most frequently asked questions during a job interview. When you can give a thoughtful answer to each question, you know that you are well prepared. This enables you to focus on having the best possible conversation. Try practicing with a friend who plays the role of the interviewer. Well, now we have discussed what you can expect during a job interview and what you can do to increase your success rate. If you want more detailed information, please find it below. [Music]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "URL ingestion for youtube links"
      ],
      "metadata": {
        "id": "Hy0oSolze_VB"
      },
      "id": "Hy0oSolze_VB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Chunking + LangChain Documents on Top the Your DataFrame"
      ],
      "metadata": {
        "id": "6Cc_3H_tg-PY"
      },
      "id": "6Cc_3H_tg-PY"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai langchain-community langsmith"
      ],
      "metadata": {
        "id": "79oO2obyfFCZ",
        "outputId": "5b5ff273-a631-4aa7-c5ec-8a0ae60b8779",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "79oO2obyfFCZ",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.45)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.8.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.4)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain langchain-openai langchain-core langchain-community\n",
        "!pip install pytube\n"
      ],
      "metadata": {
        "id": "ypllD4YghaWk",
        "outputId": "a98d9f28-0d6a-4f84-abeb-add270f8b558",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ypllD4YghaWk",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "from pytube import YouTube  # to enrich metadata from YouTube\n",
        "\n",
        "#Convert each row in df_videos (video_id, url, transcript) into multiple LangChain Documents with metadata.\n",
        "def df_to_documents(\n",
        "    df: pd.DataFrame,\n",
        "    chunk_size: int = 1000,\n",
        "    chunk_overlap: int = 150,\n",
        ") -> list[Document]:\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "    )\n",
        "\n",
        "    docs: list[Document] = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        video_id = row[\"video_id\"]\n",
        "        url = row[\"url\"]\n",
        "        transcript = row[\"transcript\"]\n",
        "\n",
        "        # Try to fetch some metadata from YouTube\n",
        "        title = author = description = None\n",
        "        try:\n",
        "            yt = YouTube(url)\n",
        "            title = yt.title\n",
        "            author = yt.author\n",
        "            description = yt.description\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # Split transcript into chunks\n",
        "        chunks = splitter.split_text(transcript)\n",
        "\n",
        "        for idx, chunk in enumerate(chunks):\n",
        "            doc = Document(\n",
        "                page_content=chunk,\n",
        "                metadata={\n",
        "                    \"video_id\": video_id,\n",
        "                    \"url\": url,\n",
        "                    \"title\": title,\n",
        "                    \"author\": author,\n",
        "                    \"description\": description,\n",
        "                    \"chunk_index\": idx,\n",
        "                },\n",
        "            )\n",
        "            docs.append(doc)\n",
        "\n",
        "    return docs\n"
      ],
      "metadata": {
        "id": "DQAyQkdpg9LU"
      },
      "id": "DQAyQkdpg9LU",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = df_to_documents(df_videos)\n",
        "print(f\"Created {len(documents)} chunks from {len(df_videos)} videos.\")"
      ],
      "metadata": {
        "id": "SRPjokEDhUVi",
        "outputId": "d257c105-5bcb-4866-c464-308f230e6bfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SRPjokEDhUVi",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 9 chunks from 2 videos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a LangChain VectorStore (Chroma) from Documents"
      ],
      "metadata": {
        "id": "ZAM2QMuAmBjJ"
      },
      "id": "ZAM2QMuAmBjJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings  # requires OPENAI_API_KEY\n",
        "\n",
        "# Or keep using SentenceTransformer embeddings if you prefer local:\n",
        "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "def build_vectorstore_from_documents(\n",
        "    docs: list[Document],\n",
        "    collection_name: str = \"youtube_rag\",\n",
        "    persist_directory: str | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Build a Chroma vector store from LangChain Documents.\n",
        "    Uses OpenAI embeddings by default.\n",
        "    \"\"\"\n",
        "    # OpenAI embedding model\n",
        "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=docs,\n",
        "        embedding=embeddings,\n",
        "        collection_name=collection_name,\n",
        "        persist_directory=persist_directory,  # can be None for in-memory\n",
        "    )\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "23CYzLAnl0ly"
      },
      "id": "23CYzLAnl0ly",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = df_to_documents(df_videos)\n",
        "vectorstore = build_vectorstore_from_documents(\n",
        "    documents,\n",
        "    collection_name=\"youtube_rag\",\n",
        "    persist_directory=\"./chroma_youtube_rag\",\n",
        ")"
      ],
      "metadata": {
        "id": "TOeHGCPpmCkR",
        "outputId": "f55dfdff-e05b-4d5b-b76d-03e94e0f5f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "id": "TOeHGCPpmCkR",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1675588897.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_videos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m vectorstore = build_vectorstore_from_documents(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcollection_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"youtube_rag\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpersist_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./chroma_youtube_rag\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3693667896.py\u001b[0m in \u001b[0;36mbuild_vectorstore_from_documents\u001b[0;34m(docs, collection_name, persist_directory)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# OpenAI embedding model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-3-small\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     vectorstore = Chroma.from_documents(\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0;34m\"api_key\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0masync_api_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             }\n\u001b[0;32m--> 399\u001b[0;31m             self.async_client = openai.AsyncOpenAI(\n\u001b[0m\u001b[1;32m    400\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0masync_specific\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    489\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fC1ZQLxdmQxQ"
      },
      "id": "fC1ZQLxdmQxQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}